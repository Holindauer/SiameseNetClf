{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling for Model 3\n",
    "\n",
    "This notebook is an alteration of the data wrangling process for model 2. With the goal of making the test set more representative of the train set. \n",
    "\n",
    "The decision to change the data wrangling process for model 3 came from the model achieving its highest validation accuracy yet (which was approximately 31% up from 25% in model 2). However, this was the first model where overfitting became a significant issue. The model was achieving aprox 65% ont he train set towards the ned of training. \n",
    "\n",
    "### There are two main possible sources for where this overfitting might be coming from:\n",
    "- The first is that I have replaced the convolutional network I defined for the encoder in models 1 and 2 with transfer learning models trained on the image net. The one I am using (which may change) is squeezenet 1.1, which did not significantly increase the amount of unique parameters in the model over all. But it is still a fairly complex model that might be too complex for the task.\n",
    "- The other possible source, which I will adress in this notebook, is that the test set I was using only contained 20/70 of the classes that appeared in the train set. I suspect this is more likely the culprit of the overfitting.\n",
    "\n",
    "In this notebook I will adjust the class distribution across the test and train set so they are more reflectant of each other. The additions to the data wrangling process are at step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def download_folder_from_s3(bucket_name, s3_folder, local_path):\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    for result in paginator.paginate(Bucket=bucket_name, Prefix=s3_folder):\n",
    "        # Download each file individually\n",
    "        for key in result.get('Contents', []):\n",
    "            file_key = key.get('Key')\n",
    "            if not os.path.exists(os.path.dirname(local_path + file_key)):\n",
    "                os.makedirs(os.path.dirname(local_path + file_key))\n",
    "            s3.download_file(bucket_name, file_key, local_path + file_key)\n",
    "\n",
    "# Example usage\n",
    "download_folder_from_s3('signature-data', 'test', 'test')\n",
    "download_folder_from_s3('signature-data', 'train', 'train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Version 1\n",
    "### 1.)\n",
    "Below I am gather the paths to all the real signatures in the train and test directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\049', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\050', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\051', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\052', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\053']\n",
      "['C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\001', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\002', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\003', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\004', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\006']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_dir = r\"C:\\Users\\hunte\\OneDrive\\Documents\\Coding Projects\\Signature-Similarity-Checker\\data\\signature-verification-dataset\\sign_data\\test\"\n",
    "train_dir = r\"C:\\Users\\hunte\\OneDrive\\Documents\\Coding Projects\\Signature-Similarity-Checker\\data\\signature-verification-dataset\\sign_data\\train\"\n",
    "\n",
    "test_dir_contents = os.listdir(test_dir)\n",
    "train_dir_contents = os.listdir(train_dir)\n",
    "\n",
    "test_real_sig_path, train_real_sig_paths = [], []\n",
    "\n",
    "# Get all the paths to the real signatures \n",
    "for subdir in test_dir_contents:\n",
    "    if \"forg\" not in subdir:\n",
    "        test_real_sig_path.append(os.path.join(test_dir, subdir))\n",
    "\n",
    "for subdir in train_dir_contents:\n",
    "    if \"forg\" not in subdir:\n",
    "        train_real_sig_paths.append(os.path.join(train_dir, subdir))\n",
    "\n",
    "\n",
    "#print first 5 paths of each list\n",
    "print(test_real_sig_path[:5])\n",
    "print(train_real_sig_paths[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.)\n",
    "I call the get_tensor_images() function to load in the list of image paths from above, apply appropriate tensor transformations to them, and return as a labels and features tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# Initializes tranforms to apply to images\n",
    "transform = transforms.ToTensor()\n",
    "resize = transforms.Resize((224, 224))\n",
    "\n",
    "\n",
    "\n",
    "def get_tensor_labels_features(tensor_image_list, path_list):\n",
    "    '''\n",
    "        This function recieves a list of paths to directories containing multiple images, where the \n",
    "        name of the directory is the label for the images in the directory. The function iterates \n",
    "        through each path, converts the images to tensors and resizes to 3x224x224, and appends them \n",
    "        to a list. The function also creates a list of labels for each image in the path. These lists \n",
    "        are converted to tensors and stacked. The function returns a tensor of labels and a tensor of\n",
    "        images.\n",
    "    '''\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # iterate through each path in the list\n",
    "    for path in path_list:\n",
    "\n",
    "        # get label from path name (last element in path)\n",
    "        label = int(path.split(\"\\\\\")[-1])\n",
    "\n",
    "        # initialize list to hold labels for each image in the path\n",
    "        dir_labels = []\n",
    "\n",
    "        # iterate through each file in the path\n",
    "        for file in os.listdir(path):\n",
    "\n",
    "            # convert image to tensor\n",
    "            tensor_image = transform(Image.open(os.path.join(path, file)))\n",
    "\n",
    "            # resize images to 224x224\n",
    "            tensor_image = resize(tensor_image)\n",
    "\n",
    "            # append tensor to list\n",
    "            tensor_image_list.append(tensor_image)\n",
    "            \n",
    "            # append single item tensors to list of labels for the path\n",
    "            dir_labels.append(torch.tensor(label))\n",
    "\n",
    "        # append list of labels to labels list after stacking\n",
    "        labels.append(torch.stack(dir_labels))\n",
    "\n",
    "    # concat list of tensor stacks into one tensor --- and stacked images into one tensor  --- and return\n",
    "    return torch.cat(labels), torch.stack(tensor_image_list)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "# intitialize lists to hold images as tensors\n",
    "test_real_sig_images, train_real_sig_images = [], []\n",
    "\n",
    "# get tensor images\n",
    "test_labels, test_images = get_tensor_labels_features(test_real_sig_images, test_real_sig_path)\n",
    "train_labels, train_images = get_tensor_labels_features(train_real_sig_images, train_real_sig_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images Shape: torch.Size([252, 3, 224, 224])\n",
      "Test Labels Shape: torch.Size([252])\n",
      "\n",
      "Train Images Shape: torch.Size([887, 3, 224, 224])\n",
      "Train Labels Shape: torch.Size([887])\n"
     ]
    }
   ],
   "source": [
    "#print shapes\n",
    "print(f'Test Images Shape: {test_images.shape}')\n",
    "print(f'Test Labels Shape: {test_labels.shape}\\n')\n",
    "\n",
    "print(f'Train Images Shape: {train_images.shape}')\n",
    "print(f'Train Labels Shape: {train_labels.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) \n",
    "Below are the new additions to the data wrangling process for model 3. It involves a process fo taking the above train and test tensors, which contain uneven distributions of classes between them, and reorganizing them to keep the 80/20 num examples split while having a uniform number of each class in each set.\n",
    "\n",
    "\n",
    "The first step is to contcatenate the images and labels toegether.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate test and train images and labels\n",
    "images = torch.cat([test_images, train_images])\n",
    "labels = torch.cat([test_labels, train_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the above image and labels tensors are passed into the below function, which reorganizes the class distribution between train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_sets(images, labels, train_split=0.8):\n",
    "    '''\n",
    "        This function iterates through the the labels tensor and extracts all unique labels.\n",
    "        These labels are then iterated through to extract out all images from the images tensor\n",
    "        that share that label. The images are then split up into the train and test sets based om\n",
    "        the train_split parameter. The function returns a train and test tensor.\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    #initialize list to hold unique labels\n",
    "    unique_labels = []\n",
    "\n",
    "    # iterate through number of examples to get unique labels\n",
    "    for i in range(len(labels)):\n",
    "\n",
    "        # get label of current iteration\n",
    "        label = int(labels[i])\n",
    "\n",
    "        if label not in unique_labels:\n",
    "            unique_labels.append(label)\n",
    "\n",
    "\n",
    "    # initialize dict to hold list of images for each unique label\n",
    "    label_img_dict = {}\n",
    "        \n",
    "    for unique_label in unique_labels:   \n",
    "\n",
    "        # intitialize list to hold images sharing a unique label\n",
    "        like_images = []\n",
    "        \n",
    "        # iterate through labels tensor\n",
    "        for (label, image) in zip(labels, images):\n",
    "\n",
    "            # convert label to int\n",
    "            label = int(label)\n",
    "\n",
    "            # append only images that share the unique label\n",
    "            if label == unique_label:\n",
    "                like_images.append(image)\n",
    "\n",
    "        # add list of images to dictionary with their label as key\n",
    "        label_img_dict[unique_label] = like_images\n",
    "\n",
    "    # initialize lists to hold train and test images\\labels\n",
    "    train_images, train_labels = [], []\n",
    "    test_images, test_labels = [], []\n",
    "\n",
    "    # iterate through dictionary of labels and images\n",
    "    for key, value in label_img_dict.items():\n",
    "\n",
    "        # compute the train split index \n",
    "        train_split_index = int(len(value) * train_split)\n",
    "\n",
    "        # append train images and labels\n",
    "        train_images.extend(value[:train_split_index])\n",
    "        train_labels.extend([key] * train_split_index)  # set num indicies in train_split to key\n",
    "\n",
    "        # append test images and labels\n",
    "        test_images.extend(value[train_split_index:]) \n",
    "        test_labels.extend([key] * (len(value) - train_split_index)) # set num indicies in test_split to key\n",
    "\n",
    "    # stack train and test images and labels\n",
    "    train_images = torch.stack(train_images)\n",
    "    train_labels = torch.stack([torch.tensor(label) for label in train_labels])\n",
    "\n",
    "    test_images = torch.stack(test_images)\n",
    "    test_labels = torch.stack([torch.tensor(label) for label in test_labels])\n",
    "\n",
    "    # return train and test images and labels\n",
    "    return train_images, train_labels, test_images, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Shape: torch.Size([885, 3, 224, 224])\n",
      "Train Labels Shape: torch.Size([885])\n",
      "\n",
      "Test Images Shape: torch.Size([254, 3, 224, 224])\n",
      "Test Labels Shape: torch.Size([254])\n"
     ]
    }
   ],
   "source": [
    "# get train and test images and labels\n",
    "train_images, train_labels, test_images, test_labels = get_train_test_sets(images, labels)\n",
    "\n",
    "# print shapes\n",
    "print(f'Train Images Shape: {train_images.shape}')\n",
    "print(f'Train Labels Shape: {train_labels.shape}\\n')\n",
    "print(f'Test Images Shape: {test_images.shape}')\n",
    "print(f'Test Labels Shape: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these are ready for training. They just need to be converted to tensor datasets and wrapped in data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tensors to file\n",
    "torch.save(test_images, \"test_images.pt\")\n",
    "torch.save(test_labels, \"test_labels.pt\")\n",
    "torch.save(train_images, \"train_images.pt\")\n",
    "torch.save(train_labels, \"train_labels.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
