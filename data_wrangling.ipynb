{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of Signature Pairs Dataset from Forged Signatures Dataset\n",
    "\n",
    "I found this dataset that consists of pngs of handwritten signatures. For each signature, there are 5 real signature instances and 5 fake signature instances. The dataset is intended for binary classification. \n",
    "\n",
    "https://www.kaggle.com/datasets/divyanshrai/handwritten-signatures \n",
    "\n",
    "What I am going to do is construct a dataset of image pairs that are labeled based on if each of those images are of the same signature or of a different signature. The resulting data will be the first data the model (which I wrote the code for yesterday) will be trained on. For now, I am not going to differentiate between real and forged signatures. Just whether the signature itself is the same. This is to determine the capacity of the model from a lower starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "\n",
    "The data directory at the beggining below contains four subdirectories inside it. Each of those subdirectories contains a directories 'forged' and 'real'.\n",
    "\n",
    "The dataset contains 30 signatures belonging to 30 people. There are 5 real signature instances by the person whose signature it is and 5 by others. \n",
    "\n",
    "The file names are 8 integers where the first 3 signifies which person did the signature, the next 2 signify which of the 5 signatures it is, and the last 3 signify whose signature it is in reality.\n",
    "\n",
    "For example: 00602023.png  That this is person 023's signature forged by person 006. And that it is the second forged signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I am loading in all the images from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of real signatures paths: 270\n",
      "length of forged signatures paths: 450\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = r\"C:\\Users\\hunte\\OneDrive\\Documents\\Coding Projects\\Signature-Similarity-Checker\\data\\handwritten-signatures\\Dataset_Signature_Final\\Dataset\"\n",
    "\n",
    "# lists to store paths of real and forged signatures\n",
    "real = []\n",
    "forged = []\n",
    "\n",
    "\n",
    "\n",
    "# gather paths of all images in the dataset\n",
    "def get_image_paths(data_dir):\n",
    "    ''' gathers image paths into two lists: real and forged based on the subfolders in the dataset'''\n",
    "    for folder in os.listdir(data_dir): # <----- this leads to 4 subdirectories, each containing a 'real' and 'forged' folder\n",
    "        for subfolder in os.listdir(os.path.join(data_dir, folder)): # <----- this leads to the 'real' and 'forged' folders\n",
    "            for file in os.listdir(os.path.join(data_dir, folder, subfolder)): # <----- this leads to the images in each of the 'real and 'forged' folders\n",
    "                if subfolder == 'real':\n",
    "                    real.append(os.path.join(data_dir, folder, subfolder, file)) # <----- append paths of real signatures to 'real' list\n",
    "                else:\n",
    "                    forged.append(os.path.join(data_dir, folder, subfolder, file)) # <----- append paths of forged signatures to 'forged' list\n",
    "\n",
    "\n",
    "# call function\n",
    "get_image_paths(data_dir)\n",
    "\n",
    "print(f'length of real signatures paths: {len(real)}')\n",
    "print(f'length of forged signatures paths: {len(forged)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.)\n",
    " Next I am checking if there are any duplicates based on the naming schema and seperating out only the unique names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are duplicates in the list of real file names.\n",
      "Out of the 270 real signatures, there are 162 unique file names.\n",
      "\n",
      "There are duplicates in the list of forged file names.\n",
      "Out of the 450 forged signatures, there are 400 unique file names.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates(image_path_list, name):\n",
    "    ''' checks for duplicates in the list of image paths\n",
    "        and returns a dict of the unique file names and \n",
    "        their paths'''\n",
    "\n",
    "    # create lists to store file names and file paths\n",
    "    file_names, file_paths = [], []\n",
    "\n",
    "    # iterate through the list of image paths\n",
    "    for path in image_path_list:\n",
    "        file_names.append(path.split('\\\\')[-1]) # <----- append the file name to the list of file names\n",
    "        file_paths.append(path)                 # <----- append the file path to the list of file paths\n",
    "\n",
    "    #check duplicates\n",
    "    if len(file_names) != len(set(file_names)):  # <----- calling set() removes duplicates\n",
    "        print(f'There are duplicates in the list of {name} file names.')\n",
    "        print(f'Out of the {len(file_names)} {name} signatures, there are {len(set(file_names))} unique file names.\\n')\n",
    "\n",
    "    # create list of only the unique file names\n",
    "    non_duplicate_names = list(set(file_names)) \n",
    "\n",
    "    # iterate through list of unique file names and once a path \n",
    "    # with its name is found, append it to the dictionary\n",
    "    unique_file_paths = {}\n",
    "\n",
    "    # iterate through the list of unique file names\n",
    "    for name in non_duplicate_names:\n",
    "        for path in file_paths: # <----- iterate through the list of file paths\n",
    "            if name in path:\n",
    "                unique_file_paths[name] = path # <----- append the file path to the dictionary with the file \n",
    "                                               #        name as the key if the file name is in the path\n",
    "     \n",
    "    return unique_file_paths\n",
    "\n",
    "\n",
    "# create dictionaries of the image paths with the name of the person as the key\n",
    "real_fnames_unique = check_duplicates(real, name='real')\n",
    "forged_fnames_unique = check_duplicates(forged, name='forged')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to check if this worked correctly by seeing if all the fnames in the paths match with the fname key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are 0 real signatures that do not match with their file name.\n"
     ]
    }
   ],
   "source": [
    "# I am going to check if this worked correctly by seeing if all the fnames in the paths match with the fname key\n",
    "# in the dictionary\n",
    "\n",
    "non_matching = 0\n",
    "\n",
    "for key, value in real_fnames_unique.items():\n",
    "    if key not in value:    \n",
    "        non_matching += 1\n",
    "\n",
    "print(f'\\n\\nThere are {non_matching} real signatures that do not match with their file name.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.)\n",
    "\n",
    "Next I am going to group together the image paths into nested lists containing only the paths to signatures beloning to the same owner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a 1 in fstring right aligned with 2 zeroes in front of it\\\n",
    "\n",
    "# create a list of the signature owner strings\n",
    "signature_owners = []\n",
    "for i in range(1, 31):\n",
    "    signature_owners.append(f'{i:0>3}') # <----- this will print i aligned with zeros padding\n",
    "                                        #        the left side of the number up to 3 digits\n",
    "\n",
    "\n",
    "def group_like_signatures(fname_path_dict_real, fname_path_dict_forged):\n",
    "    ''' Inputs are dictionaries of the real and forged signatures with keys as the file names\n",
    "    and values as the paths. The function groups the paths of signatures that belong to the \n",
    "    same person into a list of lists'''\n",
    "\n",
    "    # create a list to store the lists of paths of signatures that belong to the same person\n",
    "    nested_like_signatures_list = []\n",
    "\n",
    "    # iterate through the list of signature owners\n",
    "    for signature_owner in signature_owners:\n",
    "\n",
    "        # create a list to store the paths of signatures that belong to the same person\n",
    "        like_signatures_list = []\n",
    "\n",
    "        # iterate through the dictionary of real signatures\n",
    "        for fname, path in fname_path_dict_real.items():\n",
    "\n",
    "            if signature_owner in fname[-7:-4]:  # <----- check the last 3 digits, excluding .png\n",
    "                like_signatures_list.append(path)\n",
    "\n",
    "        # iterate through the dictionary of forged signatures\n",
    "        for fname, path in fname_path_dict_forged.items():\n",
    "                \n",
    "                if signature_owner in fname[-7:-4]: # <----- check the last 3 digits, excluding .png\n",
    "                    like_signatures_list.append(path)\n",
    "            \n",
    "        # append the list of paths of signatures that belong to the same person to the list of lists\n",
    "        nested_like_signatures_list.append(like_signatures_list) \n",
    "\n",
    "    return nested_like_signatures_list\n",
    "\n",
    "\n",
    "\n",
    "# call function to group the real and forged signatures\n",
    "nested_like_signatures_list = group_like_signatures(real_fnames_unique, forged_fnames_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.)\n",
    "next I am going to load the like images into nested lists of PIL Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# create a list to store the PIL images of signatures that belong to the same person\n",
    "nested_like_PIL_signatures = []\n",
    "\n",
    "# iterate through the list of lists of paths of signatures that belong to the same person\n",
    "for path_list in nested_like_signatures_list:\n",
    "\n",
    "    # create a list to store the PIL images of signatures that belong to the same person\n",
    "    like_PIL_signatures = []\n",
    "\n",
    "    # iterate through the list of paths of signatures that belong to the same person\n",
    "    for path in path_list:\n",
    "\n",
    "        # append the PIL image of the signature to the list of PIL images\n",
    "        like_PIL_signatures.append(Image.open(path))\n",
    "\n",
    "    # append the list of PIL images of signatures that belong to the same person to the list of lists\n",
    "    nested_like_PIL_signatures.append(like_PIL_signatures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.)   \n",
    "Next I will begin the labeling and collation process for the images loaded in. The labels will be binary. Images will be grouped into sets of two per example. An example will recieve a 1 if the two images belong to the same signature owner. Otherwise the pair will recieve a zero. \n",
    "\n",
    "The first thing I will do to accomplish this is to collate the nested list of PIL images into a list of tensor stacks. To do this I will use the ImageCollator class from image_collator.py. This applies max pooling as a dimmensionality reduction technique as well as converting all images to grayscale tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from image_collator import ImageCollator\n",
    "\n",
    "# create an instance of the ImageCollator class\n",
    "collator = ImageCollator()\n",
    "\n",
    "# collate all like PIL images into seperate tensors\n",
    "like_tensor_image_stacks = [collator.collate(PIL_image_list, num_poolings=2) for PIL_image_list in nested_like_PIL_signatures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the shapes of all the like image tensor groupings. Interestingly, contrary to the documentation of the data on kaggle, there are more than 5 forged + 5 legitimate signature images per person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1, 50, 150])\n",
      "torch.Size([26, 1, 50, 150])\n",
      "torch.Size([17, 1, 50, 150])\n",
      "torch.Size([17, 1, 50, 150])\n",
      "torch.Size([17, 1, 50, 150])\n",
      "torch.Size([17, 1, 50, 150])\n",
      "torch.Size([17, 1, 50, 150])\n",
      "torch.Size([23, 1, 50, 150])\n",
      "torch.Size([18, 1, 50, 150])\n",
      "torch.Size([20, 1, 50, 150])\n",
      "torch.Size([17, 1, 50, 150])\n",
      "torch.Size([17, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([20, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([15, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n",
      "torch.Size([10, 1, 50, 150])\n"
     ]
    }
   ],
   "source": [
    "for tensor in like_tensor_image_stacks:\n",
    "    print(tensor.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.)   \n",
    "Next I will take that list of tensor stacks and use the Build_Batch class in get_batch.py. Labels will not be applied with this step.\n",
    "\n",
    "This will be done in two ways. The first will use the .build_like_pairs() method to group all possible like signatures together into pairs of images labeled as 1. The method takes a single tensors stack of like images and outputs a single stack of these combinations. This is done to the entire list of tensors.\n",
    "\n",
    "Below I map the .build_like_pairs() method on each of the tensor stacks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_batch import Build_Batch\n",
    "\n",
    "# create an instance of the Build_Batch class\n",
    "builder = Build_Batch()\n",
    "\n",
    "# map the build_like_pairs method to the list of like tensor image stacks\n",
    "like_tensor_combos = map(builder.build_like_pairs, like_tensor_image_stacks)\n",
    "\n",
    "# convert the map object to a list\n",
    "like_tensor_combos = list(like_tensor_combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the output tensors are of the shape (num_examples, 2 images, 1 singleton, height, width)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 stacks of like signature combinations.\n",
      "torch.Size([420, 2, 1, 50, 150])\n",
      "torch.Size([650, 2, 1, 50, 150])\n",
      "torch.Size([272, 2, 1, 50, 150])\n",
      "torch.Size([272, 2, 1, 50, 150])\n",
      "torch.Size([272, 2, 1, 50, 150])\n",
      "torch.Size([272, 2, 1, 50, 150])\n",
      "torch.Size([272, 2, 1, 50, 150])\n",
      "torch.Size([506, 2, 1, 50, 150])\n",
      "torch.Size([306, 2, 1, 50, 150])\n",
      "torch.Size([380, 2, 1, 50, 150])\n",
      "torch.Size([272, 2, 1, 50, 150])\n",
      "torch.Size([272, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([380, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([210, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n",
      "torch.Size([90, 2, 1, 50, 150])\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(like_tensor_combos)} stacks of like signature combinations.')\n",
    "\n",
    "# print all shapes of the like tensors\n",
    "for tensor in like_tensor_combos:\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am taking the list of person segregated like image pair tensor stacks and stacking them all into a single tensor. These are the positive examples of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the like tensor combos after concatenating is torch.Size([6196, 2, 1, 50, 150]).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#concatenate all the like tensors into one tensor\n",
    "like_tensor_combos = torch.cat(like_tensor_combos, dim=0)\n",
    "\n",
    "print(f'The shape of the like tensor combos after concatenating is {like_tensor_combos.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.)   \n",
    "I am now going build a stack of unlike image pairs with the .build|_unlike_pairs() class.   \n",
    "\n",
    "As the name suggests, it returns a tensor stack of all combinations of pairs between images not belonging to like signature owners. \n",
    "\n",
    "Currently, a weakness in the algorithm I am using to do this is that it does not check for duplicate examples.   \n",
    "\n",
    "Duplicates present two issues: The first is that duplicates mean that in a single epoch, the model will predict on the same examples multiple times and this will affect the learning update. The way that the learning update will be affected is essentially the same as letting the gradients accumulate for longer before applying the weight update. Not particularly harmful but leads to less control over training.\n",
    "\n",
    "The other way that training is affected is a bit more insidious. That being that if there are dupliicates of the same example in the tiraning set and the test set, then that will affect the model evaluation and lead to less of an understanding of how to improve the model. \n",
    "\n",
    "I will adress this soon. For now thought I want to develop out a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the unlike tensor combos is torch.Size([171466, 2, 1, 50, 150]).\n"
     ]
    }
   ],
   "source": [
    "unlike_tensor_combos = builder.build_unlike_pairs(like_tensor_image_stacks)\n",
    "\n",
    "print(f'The shape of the unlike tensor combos is {unlike_tensor_combos.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.)   \n",
    "Next, i am going to create a test and train split for the each of the like and unlike tensor combos. I'm doing this seperately for the two labels so that I can control the distribution of labels in each of these sets. I will also creates the labels for these tensors here as well. They will be seperate a seperate tensor from the feature tensors. This is so they can easily be wrapped in a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split(tensor_combos, like_or_unlike):\n",
    "    ''' splits the tensor combos into training and validation sets\n",
    "        and creates labels for the tensors'''\n",
    "\n",
    "    #compute 80 percent of the length of the unlike tensor combos\n",
    "    eighty_percent = int(0.8 * len(tensor_combos))\n",
    "\n",
    "    #split the unlike tensor combos into training and validation sets\n",
    "    train = tensor_combos[:eighty_percent]\n",
    "    val = tensor_combos[eighty_percent:]\n",
    "\n",
    "    # create labels for the unlike or like tensors depending on the input\n",
    "    if like_or_unlike == 'unlike':\n",
    "        # create labels for the unlike tensors\n",
    "        train_labels = torch.zeros(len(train))\n",
    "        val_labels = torch.zeros(len(val))\n",
    "    elif like_or_unlike == 'like':\n",
    "        # create labels for the like tensors\n",
    "        train_labels = torch.ones(len(train))\n",
    "        val_labels = torch.ones(len(val))\n",
    "\n",
    "    return train, val, train_labels, val_labels\n",
    "\n",
    "\n",
    "# split like tesnors\n",
    "like_train, like_val, like_train_labels, like_val_labels = split(like_tensor_combos, like_or_unlike = 'like')\n",
    "\n",
    "# split unlike tensors\n",
    "unlike_train, unlike_val, unlike_train_labels, unlike_val_labels = split(unlike_tensor_combos, like_or_unlike='unlike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The shape of the like training set is torch.Size([4956, 2, 1, 50, 150]).\n",
      "The shape of the like validation set is torch.Size([1240, 2, 1, 50, 150]).\n",
      "Then shape og the like train labels is torch.Size([4956]).\n",
      "Then shape og the like val labels set is torch.Size([1240]).\n",
      "\n",
      "\n",
      "The shape of the unlike training set is torch.Size([137172, 2, 1, 50, 150]).\n",
      "The shape of the unlike validation set is torch.Size([34294, 2, 1, 50, 150]).\n",
      "Then shape og the unlike train labels is torch.Size([137172]).\n",
      "Then shape og the unlike val labels set is torch.Size([34294]).\n"
     ]
    }
   ],
   "source": [
    "def print_shapes(train_, val_, train_labels_, val_labels_, condition):\n",
    "    ''' prints the shapes of the training and validation sets and their labels'''\n",
    "    # print shapes\n",
    "    print(f'\\n\\nThe shape of the {condition} training set is {train_.shape}.')\n",
    "    print(f'The shape of the {condition} validation set is {val_.shape}.')\n",
    "    print(f'Then shape og the {condition} train labels is {train_labels_.shape}.')\n",
    "    print(f'Then shape og the {condition} val labels set is {val_labels_.shape}.')\n",
    "\n",
    "# print shapes of like tensors\n",
    "print_shapes(like_train, like_val, like_train_labels, like_val_labels, condition = 'like')\n",
    "\n",
    "# print shapes of unlike tensors\n",
    "print_shapes(unlike_train, unlike_val, unlike_train_labels, unlike_val_labels, condition = 'unlike')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here I am concatenating the like and unlike for train and for val each into unified data splits. For both targets and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the like and unlike training features and labels\n",
    "train = torch.cat((like_train, unlike_train), dim=0)\n",
    "train_labels = torch.cat((like_train_labels, unlike_train_labels), dim=0)\n",
    "\n",
    "#concatenate the like and unlike validation sets and labels\n",
    "val = torch.cat((like_val, unlike_val), dim=0)\n",
    "val_labels = torch.cat((like_val_labels, unlike_val_labels), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrangling is done. They will be wrapped in data loaders before running training which will take care of shuffling examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training set is torch.Size([142128, 2, 1, 50, 150]).\n",
      "The shape of the training labels is torch.Size([142128]).\n",
      "\n",
      "The shape of the validation set is torch.Size([35534, 2, 1, 50, 150]).\n",
      "The shape of the validation labels is torch.Size([35534]).\n"
     ]
    }
   ],
   "source": [
    "# print shapes\n",
    "print(f'The shape of the training set is {train.shape}.')\n",
    "print(f'The shape of the training labels is {train_labels.shape}.\\n')\n",
    "\n",
    "print(f'The shape of the validation set is {val.shape}.')\n",
    "print(f'The shape of the validation labels is {val_labels.shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# make a data directory\n",
    "os.mkdir(os.path.join(cwd, 'data'))\n",
    "\n",
    "# save the training and validation sets to the data directory\n",
    "torch.save(train, os.path.join(cwd, 'data', 'train_examples.pt'))\n",
    "torch.save(train_labels, os.path.join(cwd, 'data', 'train_labels.pt'))\n",
    "torch.save(val, os.path.join(cwd, 'data', 'val_examples.pt'))\n",
    "torch.save(val_labels, os.path.join(cwd, 'data', 'val_labels.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
