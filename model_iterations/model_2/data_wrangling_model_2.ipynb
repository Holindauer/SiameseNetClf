{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling for Model 2\n",
    "\n",
    "This notebook was made following the completion of my redesign of model 1 (done using mnist). It contains the data preperation for use in training model 2. \n",
    "\n",
    "The goal is to get the data into the same format as mnist when you load it in using torch. That is, integer encoded labels.\n",
    "\n",
    "The data that I am using comes from: https://www.kaggle.com/datasets/robinreni/signature-verification-dataset It is the same data as what I used for model 1, but this version has been processed into a far better storage structure. The dataset contains real and forged signatures for 70 people. The signature for each person (for both real and forged) are grouped into their own subdirectories.\n",
    "\n",
    "I will prep one of two versions of the dataset from this dataset now. The first version will only include the real signatures. It will be labeled with integer encoding based on who the signatre belongs to. \n",
    "\n",
    "The second version, which I will save making until I can train a model on the first, will contain both real and forged versions of the datset. Signatures of the same person but different forgery status will be considered different classes. Also labeled with integer encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def download_folder_from_s3(bucket_name, s3_folder, local_path):\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    for result in paginator.paginate(Bucket=bucket_name, Prefix=s3_folder):\n",
    "        # Download each file individually\n",
    "        for key in result.get('Contents', []):\n",
    "            file_key = key.get('Key')\n",
    "            if not os.path.exists(os.path.dirname(local_path + file_key)):\n",
    "                os.makedirs(os.path.dirname(local_path + file_key))\n",
    "            s3.download_file(bucket_name, file_key, local_path + file_key)\n",
    "\n",
    "# Example usage\n",
    "download_folder_from_s3('signature-data', 'test', 'test')\n",
    "download_folder_from_s3('signature-data', 'train', 'train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Version 1\n",
    "Below I am gather the paths to all the real signatures in the train and test directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\049', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\050', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\051', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\052', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\test\\\\053']\n",
      "['C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\001', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\002', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\003', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\004', 'C:\\\\Users\\\\hunte\\\\OneDrive\\\\Documents\\\\Coding Projects\\\\Signature-Similarity-Checker\\\\data\\\\signature-verification-dataset\\\\sign_data\\\\train\\\\006']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_dir = r\"C:\\Users\\hunte\\OneDrive\\Documents\\Coding Projects\\Signature-Similarity-Checker\\data\\signature-verification-dataset\\sign_data\\test\"\n",
    "train_dir = r\"C:\\Users\\hunte\\OneDrive\\Documents\\Coding Projects\\Signature-Similarity-Checker\\data\\signature-verification-dataset\\sign_data\\train\"\n",
    "\n",
    "test_dir_contents = os.listdir(test_dir)\n",
    "train_dir_contents = os.listdir(train_dir)\n",
    "\n",
    "test_real_sig_path, train_real_sig_paths = [], []\n",
    "\n",
    "# Get all the paths to the real signatures \n",
    "for subdir in test_dir_contents:\n",
    "    if \"forg\" not in subdir:\n",
    "        test_real_sig_path.append(os.path.join(test_dir, subdir))\n",
    "\n",
    "for subdir in train_dir_contents:\n",
    "    if \"forg\" not in subdir:\n",
    "        train_real_sig_paths.append(os.path.join(train_dir, subdir))\n",
    "\n",
    "\n",
    "#print first 5 paths of each list\n",
    "print(test_real_sig_path[:5])\n",
    "print(train_real_sig_paths[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I call the get_tensor_images() function to load in the list of image paths from above, apply appropriate tensor transformations to them, and return as a labels and features tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# Initializes tranforms to apply to images\n",
    "transform = transforms.ToTensor()\n",
    "resize = transforms.Resize((224, 224))\n",
    "\n",
    "\n",
    "\n",
    "def get_tensor_labels_features(tensor_image_list, path_list):\n",
    "    '''\n",
    "        This function recieves a list of paths to directories containing multiple images, where the \n",
    "        name of the directory is the label for the images in the directory. The function iterates \n",
    "        through each path, converts the images to tensors and resizes to 3x224x224, and appends them \n",
    "        to a list. The function also creates a list of labels for each image in the path. These lists \n",
    "        are converted to tensors and stacked. The function returns a tensor of labels and a tensor of\n",
    "        images.\n",
    "    '''\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # iterate through each path in the list\n",
    "    for path in path_list:\n",
    "\n",
    "        # get label from path name (last element in path)\n",
    "        label = int(path.split(\"\\\\\")[-1])\n",
    "\n",
    "        # initialize list to hold labels for each image in the path\n",
    "        dir_labels = []\n",
    "\n",
    "        # iterate through each file in the path\n",
    "        for file in os.listdir(path):\n",
    "\n",
    "            # convert image to tensor\n",
    "            tensor_image = transform(Image.open(os.path.join(path, file)))\n",
    "\n",
    "            # resize images to 224x224\n",
    "            tensor_image = resize(tensor_image)\n",
    "\n",
    "            # append tensor to list\n",
    "            tensor_image_list.append(tensor_image)\n",
    "            \n",
    "            # append single item tensors to list of labels for the path\n",
    "            dir_labels.append(torch.tensor(label))\n",
    "\n",
    "        # append list of labels to labels list after stacking\n",
    "        labels.append(torch.stack(dir_labels))\n",
    "\n",
    "    # concat list of tensor stacks into one tensor --- and stacked images into one tensor  --- and return\n",
    "    return torch.cat(labels), torch.stack(tensor_image_list)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "# intitialize lists to hold images as tensors\n",
    "test_real_sig_images, train_real_sig_images = [], []\n",
    "\n",
    "# get tensor images\n",
    "test_labels, test_images = get_tensor_labels_features(test_real_sig_images, test_real_sig_path)\n",
    "train_labels, train_images = get_tensor_labels_features(train_real_sig_images, train_real_sig_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images Shape: torch.Size([252, 3, 224, 224])\n",
      "Test Labels Shape: torch.Size([252])\n",
      "\n",
      "Train Images Shape: torch.Size([887, 3, 224, 224])\n",
      "Train Labels Shape: torch.Size([887])\n"
     ]
    }
   ],
   "source": [
    "#print shapes\n",
    "print(f'Test Images Shape: {test_images.shape}')\n",
    "print(f'Test Labels Shape: {test_labels.shape}\\n')\n",
    "\n",
    "print(f'Train Images Shape: {train_images.shape}')\n",
    "print(f'Train Labels Shape: {train_labels.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's left to do before conducting training is to convert these tensors to tensor datasets and wrap in dataloaders, which should be done in the training environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tensors to file\n",
    "torch.save(test_images, \"test_images.pt\")\n",
    "torch.save(test_labels, \"test_labels.pt\")\n",
    "torch.save(train_images, \"train_images.pt\")\n",
    "torch.save(train_labels, \"train_labels.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
